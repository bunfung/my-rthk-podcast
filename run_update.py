#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RTHK ã€Šè¬›æ±è¬›è¥¿ã€‹Podcast ä¸»æ›´æ–°è…³æœ¬
æµç¨‹ï¼š
  1. è®€å– last_checked.json å–å¾—ä¸Šæ¬¡æª¢æŸ¥æ—¥æœŸ
  2. å¾ RTHK æŠ“å–æ¯”ä¸Šæ¬¡æ›´æ–°çš„é›†æ•¸
  3. ç¬¦åˆä¸»æŒäººæ¢ä»¶ AND å””åœ¨ ia_mapping.json â†’ ä¸‹è¼‰ MP3
  4. ä¸Šå‚³åˆ° Internet Archive
  5. åŠ å…¥ ia_mapping.json + æ›´æ–° last_checked.json
  6. è¼¸å‡ºçµ±è¨ˆåˆ° /tmp/rthk_update_stats.json
"""
import os
import re
import json
import time
import logging
import subprocess
import requests
from datetime import datetime, date
from urllib.parse import quote

# â”€â”€ è¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_DIR = '/home/ubuntu/rthk_podcast'
MP3_DIR = f'{BASE_DIR}/mp3'
IA_MAPPING_FILE = f'{BASE_DIR}/ia_mapping.json'
LAST_CHECKED_FILE = f'{BASE_DIR}/last_checked.json'
STATS_FILE = '/tmp/rthk_update_stats.json'

CHANNEL = 'radio1'
PROGRAMME = 'Free_as_the_wind'
BASE_URL = 'https://www.rthk.hk'
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',
    'Referer': f'https://www.rthk.hk/radio/{CHANNEL}/programme/{PROGRAMME}',
}

ALLOWED_HOSTS = ['è˜‡å¥­', 'é‚±é€¸', 'é¦¬é¼ç››', 'é¦®å¤©æ¨‚']

IA_ACCESS_KEY = os.environ.get('IA_ACCESS_KEY', 'kFTwDB2nXEGiWNYZ')
IA_SECRET_KEY = os.environ.get('IA_SECRET_KEY', 'gPTTPew6CA8WyEXn')

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'{BASE_DIR}/update.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


# â”€â”€ å·¥å…·å‡½æ•¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def parse_date(s):
    try:
        return datetime.strptime(s, '%d/%m/%Y').date()
    except:
        return None


def clean_html(text):
    return re.sub(r'<[^>]+>', '', text).strip()


def load_json(path, default):
    try:
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except:
        return default


def save_json(path, data):
    with open(path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


# â”€â”€ RTHK æŠ“å– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_available_months():
    from bs4 import BeautifulSoup
    url = f'{BASE_URL}/radio/{CHANNEL}/programme/{PROGRAMME}'
    resp = requests.get(url, headers=HEADERS, timeout=30)
    soup = BeautifulSoup(resp.text, 'html.parser')
    months = []
    select = soup.find('select', class_='selMonWrap')
    if select:
        for opt in select.find_all('option'):
            val = opt.get('value', '').strip()
            if val and len(val) == 6:
                months.append(val)
    return sorted(months, reverse=True)


def get_episodes_by_month(ym):
    url = f'{BASE_URL}/radio/catchUpByMonth'
    params = {'c': CHANNEL, 'p': PROGRAMME, 'm': ym}
    resp = requests.get(url, params=params, headers=HEADERS, timeout=30)
    data = resp.json()
    if data.get('status') == '1':
        return data.get('content', [])
    return []


def check_host_qualification(ep_id):
    """
    æª¢æŸ¥é›†æ•¸æ˜¯å¦ç¬¦åˆä¸»æŒäººæ¢ä»¶
    è¿”å› (qualify: bool, matched: list)
    """
    url = f'{BASE_URL}/radio/{CHANNEL}/programme/{PROGRAMME}/episode/{ep_id}'
    try:
        resp = requests.get(url, headers=HEADERS, timeout=15)
        text = resp.text

        ep_hosts = []
        ep_guests = []
        programme_hosts = []

        pop_match = re.search(r'popEpiTit.*?</div>\s*</div>\s*</div>', text, re.DOTALL)
        if pop_match:
            section = pop_match.group(0)
            epidesc_match = re.search(r'epidesc.*?</div>', section, re.DOTALL)
            if epidesc_match:
                epidesc = epidesc_match.group(0)
                ep_hosts = [clean_html(h) for h in re.findall(r'(?<![äºº])ä¸»æŒ[ï¼š:]([^\n<\r]+)', epidesc) if clean_html(h)]
                ep_guests = [clean_html(g) for g in re.findall(r'å˜‰è³“[ï¼š:]([^\n<\r]+)', epidesc) if clean_html(g)]
            programme_hosts = [clean_html(h) for h in re.findall(r'ä¸»æŒäºº[ï¼š:]([^\n<\r]+)', section) if clean_html(h)]

        check_people = (ep_hosts + ep_guests) if ep_hosts else programme_hosts
        matched = [h for h in ALLOWED_HOSTS if any(h in p for p in check_people)]
        return len(matched) > 0, matched

    except Exception as e:
        logger.error(f'æª¢æŸ¥ä¸»æŒäººå¤±æ•— (ep_id={ep_id}): {e}')
        return False, []


def get_audio_url(ep_id):
    """ç²å–é›†æ•¸çš„éŸ³é » URL"""
    url = f'{BASE_URL}/radio/getEpisode'
    params = {'c': CHANNEL, 'p': PROGRAMME, 'e': ep_id}
    resp = requests.get(url, params=params, headers=HEADERS, timeout=30)
    urls = re.findall(r'https://rthkaod2022[^"\']+master\.m3u8[^"\']*', resp.text)
    # å„ªå…ˆé¸å†‡ start= çš„ URLï¼ˆå®Œæ•´é›†æ•¸ï¼‰
    for u in urls:
        if 'start=' not in u:
            return u
    return urls[0] if urls else None


# â”€â”€ ä¸‹è¼‰ MP3 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def download_mp3(ep_id, audio_url, title):
    """ç”¨ ffmpeg ä¸‹è¼‰ MP3ï¼Œè¿”å›è·¯å¾‘æˆ– None"""
    os.makedirs(MP3_DIR, exist_ok=True)
    mp3_path = f'{MP3_DIR}/{ep_id}_0.mp3'
    tmp_path = mp3_path + '.tmp'

    cmd = ['ffmpeg', '-loglevel', 'error', '-i', audio_url,
           '-vn', '-acodec', 'libmp3lame', '-ab', '64k', '-ar', '44100',
           '-f', 'mp3', '-y', tmp_path]
    try:
        result = subprocess.run(cmd, timeout=600, capture_output=True)
        if result.returncode == 0 and os.path.exists(tmp_path) and os.path.getsize(tmp_path) > 100000:
            os.rename(tmp_path, mp3_path)
            size_mb = os.path.getsize(mp3_path) / 1024 / 1024
            logger.info(f'  âœ… ä¸‹è¼‰å®Œæˆ: {size_mb:.1f}MB')
            return mp3_path
        else:
            logger.error(f'  âŒ ä¸‹è¼‰å¤±æ•—: returncode={result.returncode}')
            if os.path.exists(tmp_path):
                os.remove(tmp_path)
            return None
    except Exception as e:
        logger.error(f'  âŒ ä¸‹è¼‰éŒ¯èª¤: {e}')
        return None


# â”€â”€ ä¸Šå‚³åˆ° IA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def upload_to_ia(ep_id, mp3_path, title, ep_date):
    """ä¸Šå‚³ MP3 åˆ° Internet Archiveï¼Œè¿”å› ia_info dict æˆ– None"""
    item_id = f'rthk-jiang-dong-jiang-xi-{ep_id}'
    filename = f'{ep_id}_0.mp3'
    file_size = os.path.getsize(mp3_path)

    try:
        day, month, year = ep_date.split('/')
        iso_date = f'{year}-{month}-{day}'
    except:
        iso_date = ep_date

    def enc(v):
        return f"uri({quote(v, safe='')})"

    headers = {
        'Authorization': f'LOW {IA_ACCESS_KEY}:{IA_SECRET_KEY}',
        'x-archive-meta-mediatype': 'audio',
        'x-archive-meta-collection': 'opensource_audio',
        'x-archive-meta-title': enc(f'RTHK è¬›æ±è¬›è¥¿ - {title} ({ep_date})'),
        'x-archive-meta-creator': enc('RTHK Radio 1'),
        'x-archive-meta-subject': enc('podcast;RTHK;è¬›æ±è¬›è¥¿;é¦™æ¸¯é›»å°'),
        'x-archive-meta-description': enc(f'é¦™æ¸¯é›»å°ç¬¬ä¸€å°ã€Šè¬›æ±è¬›è¥¿ã€‹ç¯€ç›® - {title}ï¼Œæ’­å‡ºæ—¥æœŸï¼š{ep_date}'),
        'x-archive-meta-language': 'zho',
        'x-archive-meta-date': iso_date,
        'x-archive-auto-make-bucket': '1',
        'Content-Type': 'audio/mpeg',
        'Content-Length': str(file_size),
    }

    upload_url = f'https://s3.us.archive.org/{item_id}/{filename}'
    with open(mp3_path, 'rb') as f:
        resp = requests.put(upload_url, data=f, headers=headers, timeout=600)

    if resp.status_code in [200, 201]:
        ia_url = f'https://archive.org/download/{item_id}/{filename}'
        logger.info(f'  âœ… ä¸Šå‚³æˆåŠŸ: {ia_url}')
        return {
            'item_id': item_id,
            'url': ia_url,
            'size': file_size,
            'title': title,
            'date': ep_date
        }
    else:
        logger.error(f'  âŒ ä¸Šå‚³å¤±æ•— HTTP {resp.status_code}: {resp.text[:200]}')
        return None


# â”€â”€ ä¸»æµç¨‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    # è®€å–ç¾æœ‰è¨˜éŒ„
    ia_mapping = load_json(IA_MAPPING_FILE, {})
    last_checked = load_json(LAST_CHECKED_FILE, {'last_checked_date': '01/10/2025'})
    last_checked_date = parse_date(last_checked.get('last_checked_date', '01/10/2025'))

    logger.info(f'ä¸Šæ¬¡æª¢æŸ¥æ—¥æœŸ: {last_checked_date}')
    logger.info(f'ia_mapping ç¾æœ‰: {len(ia_mapping)} é›†')

    # çµ±è¨ˆ
    stats = {'new_episodes': 0, 'downloaded': 0, 'uploaded': 0, 'failed': 0, 'uploaded_titles': []}
    latest_date_seen = last_checked_date

    # ç²å–å¯ç”¨æœˆä»½
    months = get_available_months()
    logger.info(f'å¯ç”¨æœˆä»½: {months}')

    for ym in months:
        year, month = int(ym[:4]), int(ym[4:])
        ym_date = date(year, month, 1)
        last_ym_date = date(last_checked_date.year, last_checked_date.month, 1)

        # æ—©æ–¼ä¸Šæ¬¡æª¢æŸ¥æœˆä»½ï¼Œåœæ­¢
        if ym_date < last_ym_date:
            logger.info(f'æœˆä»½ {ym} æ—©æ–¼ä¸Šæ¬¡æª¢æŸ¥æœˆä»½ï¼Œåœæ­¢')
            break

        logger.info(f'æª¢æŸ¥ {ym}...')
        episodes = get_episodes_by_month(ym)

        for ep in episodes:
            ep_id = str(ep.get('id', ''))
            ep_date_str = ep.get('date', '')
            title = ep.get('title', 'æœªçŸ¥')
            ep_date = parse_date(ep_date_str)

            if not ep_date or not ep_id:
                continue

            # åªè™•ç†æ¯”ä¸Šæ¬¡æ›´æ–°çš„é›†æ•¸
            if ep_date <= last_checked_date:
                continue

            # æ›´æ–°ä»Šæ¬¡è¦‹åˆ°çš„æœ€æ–°æ—¥æœŸ
            if ep_date > latest_date_seen:
                latest_date_seen = ep_date

            logger.info(f'æ–°é›†æ•¸: {ep_date_str} - {title} (ID: {ep_id})')
            stats['new_episodes'] += 1

            # å·²åœ¨ ia_mappingï¼Œè·³é
            if ep_id in ia_mapping:
                logger.info(f'  å·²åœ¨ ia_mappingï¼Œè·³é')
                continue

            # æª¢æŸ¥ä¸»æŒäººæ¢ä»¶
            qualify, matched = check_host_qualification(ep_id)
            time.sleep(0.5)

            if not qualify:
                logger.info(f'  âŒ å””ç¬¦åˆä¸»æŒäººæ¢ä»¶ï¼Œè·³é')
                continue

            logger.info(f'  âœ… ç¬¦åˆæ¢ä»¶ (åŒ¹é…: {matched})')

            # ç²å–éŸ³é » URL
            audio_url = get_audio_url(ep_id)
            if not audio_url:
                logger.error(f'  âŒ ç„¡æ³•ç²å–éŸ³é » URL')
                stats['failed'] += 1
                continue

            # ä¸‹è¼‰ MP3
            logger.info(f'  ä¸‹è¼‰ MP3...')
            mp3_path = download_mp3(ep_id, audio_url, title)
            if not mp3_path:
                stats['failed'] += 1
                continue
            stats['downloaded'] += 1

            # ä¸Šå‚³åˆ° IA
            logger.info(f'  ä¸Šå‚³åˆ° IA...')
            ia_info = upload_to_ia(ep_id, mp3_path, title, ep_date_str)
            if not ia_info:
                stats['failed'] += 1
                continue

            # åŠ å…¥ ia_mapping ä¸¦ç«‹å³å„²å­˜
            ia_mapping[ep_id] = ia_info
            save_json(IA_MAPPING_FILE, ia_mapping)
            stats['uploaded'] += 1
            stats['uploaded_titles'].append(f'{title} ({ep_date_str})')
            logger.info(f'  âœ… å·²è¨˜éŒ„åˆ° ia_mapping.json')

            # ä¸‹è¼‰å¾Œåˆªé™¤æœ¬åœ° MP3ï¼ˆç¯€çœç©ºé–“ï¼ŒIA å·²æœ‰å‚™ä»½ï¼‰
            try:
                os.remove(mp3_path)
                logger.info(f'  ğŸ—‘ï¸  å·²åˆªé™¤æœ¬åœ° MP3')
            except:
                pass

            time.sleep(2)

    # æ›´æ–° last_checked.json
    if latest_date_seen > last_checked_date:
        new_last_checked = {
            'last_checked_date': latest_date_seen.strftime('%d/%m/%Y'),
            'updated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'note': 'åªè¨˜éŒ„æ—¥æœŸï¼Œå””è¨˜éŒ„ IDï¼ˆID ä¿‚å…¨å°å…±ç”¨æµæ°´è™Ÿï¼‰'
        }
        save_json(LAST_CHECKED_FILE, new_last_checked)
        logger.info(f'å·²æ›´æ–° last_checked_date è‡³ {latest_date_seen.strftime("%d/%m/%Y")}')
    else:
        logger.info('ä»Šæ¬¡å†‡è¦‹åˆ°æ›´æ–°çš„æ—¥æœŸï¼Œlast_checked.json ä¿æŒä¸è®Š')

    # è¼¸å‡ºçµ±è¨ˆ
    save_json(STATS_FILE, stats)
    logger.info(f'å®Œæˆï¼æ–°é›†æ•¸={stats["new_episodes"]}, ä¸‹è¼‰={stats["downloaded"]}, ä¸Šå‚³={stats["uploaded"]}, å¤±æ•—={stats["failed"]}')


if __name__ == '__main__':
    main()
